# 161 notes
===========
# Lecture 1:
first bunch of lectures is about search
  - heuristics: way of telling computer how to solve these problems in an intuitive way
constraint satisfaction ^ part of search
end of first half of the course = game play

first bunch of lectures is about search
  - heuristics: way of telling computer how to solve these problems in an intuitive way


winograd schemas: alternative to turing test
  - given a story (some words are blanked out)
    - knowing things outside of the sentence itself helps you figure out which word is what answer
    - the trophy doesnt fit into the brown suitcase because it's too [smal/large]. what is too [small/large]

pros of winograd over turing test
  - weaknesses of turing test
    - deception, converstaion, evaluation
      - false identity != intelligence. conversation does not require intelligent reasoning, evaluation is not intelligence

AI = intelligent rational agents
  - input -> select action to maximize performance -> given the input and whatever built-in knowledge it has


rest of the lecture = AI ethical issues examples (non-technical)


# Lecture 2:
search problem + search strategy get fed into the search engine and output solution
search problem TODAY:
- initial state
- final/goal state or goal test/predicate
- actions
- transition model/successors
- costs

task = find sequence of actions to move from initial state to goal state 

NOT COMPLETED NOTES


# Lecture 3:
how to go from real world problem -> search problem
find the initial state, goal state
8-queens problem
- initial state = empty board
- goal state = we don't know (we only know the goal predicate)
  - function that given a state tells you whether you've done a good job or not
  - easier for the 8-queens problem
- action = place queen on the board
- branching factor + size of search tree = measurement to tell how difficult the problem is
- from inital state there is 64 possibilities and branches
  - branching factor = 64 * 63 * 62....57
  - 10^14 size search tree
- we can reduce this because there aren't technially 63 problems where the next queen could be
  - there are actually only 8 options
  - we are reducing the width of possible actions here
  - 2057 possibilities now
if there are 100 queens it goes from 10^400 to 10^52
  - when we do local search algorithms we will learn how to solve the 1e6 queens problem
  - local search instead of absolute search algorithms
technically a ITERATIVE STATE FORMULATION

another possibility: 
  - initial state = 8 queens already on the board
  - action = move a queen so that it is not attacked by another queen on the board
  - called a complete state formulation because we only care about 

# Discussion 1:
watched discusion 1A to learn introductory LISP
few notes on CLISP syntax

Atom vs S-Expression

examples of atoms:
- 30
- "Hello!"
- t
- nil
- A (error not defined)
- :A (symbol)
- 999999
- #b111
- #x111
- approx around 8 minutes in dis 1a recording

examples of s-expressions:
- (f x y z ...)
- f is the function and x y z are the arguments
  - f could be something like +
  - (+ 1 2 3 4) -> 1 + 2 + 3 + 4 = 10

quotes are lazy expressions
(+ 1 2) evaluates immediately to 3
but '(+ 1 2) only evaluates to 3 after the eval function is called on it

(= 1 2) (and T nil) are all boolean expressions that can be used

(concatenate 'string "HELLO," "world!") => "Hello,world!"
(format nil "Hello,~a" "Alice") => "Hello,Alice"
video @ 16min = weird printing and returning stuff

## variables:
(defparameter age 35)
(defvar newage 20) << only first time declaration (all other after defvars wont work)
(setq newage 30) definition or redefinition

## lists:
(cons 1 (cons 2 (cons 3 nil))) -> '(1 2 3)
(list 1 2 3) does the same thing

append/concatenate/car/cdr are all functions that have to do with lists
car/cdr are like first/rest (look up later)

## functions:
(defun hello(name)(format nil "Hello, ~A" name))
(hello "Bob") -> "Hello, Bob"

## conditionals/control flow
(if(equal *name* "bob")
  "ok"
  "no")
if then else expression ^^
can also you cond instead of if (23:17 on the dis 1A lecture)

## recursion factorial
(defun factorial(n)# 
  (if (< n 2)
    1
    (* n (factorial(- n 1)))
  )
)
(factorial 5) -> 120

next few examples = all recursion examples that do different things
JSCL is good github for CLISP practice! so is brew clisp that i have on here as well


# Lecture 4
Uninformed Search: search problem + search strategy get fed through search engine to solution
EXPAND state = consider all possible actions
GENERATE = generating children of the previous EXPAND state
FRINGE/FRONTIER = nodes that have been expanded but not generated (may have solution but no idea)
searching = which state to expand

tree search algorithm: frontier = initial state. if frontier empty return fail, node = choose leaf. if node is goal state, return node state. frontier is now the expansion of the node.
^^ similar to a dfs algorithm?? maybe??

graph search algorithm: same as tree search. add chosen leaf to explored set and only add new nodes to frontier (not ones that have already been explored)

branching factor = b, depth = d, nodes = N(b, d) = O(b^d)

BFS = choose the leftmost node and work your way to the right; use a queue to represent. FIFO
seperation property: 3 types of nodes: 1 = nodes already visited, 2 = frontier, 3 = all other nodes. to go from 1 to 3 you have to go through 2.

if goal test happens on expand, O(b^d+1). if goal test happens on generate, O(b^d)
  d is optimal solution depth, b is branching factor

# Lecture 5
wrap up of uninformed search
variant of uninformed search = BFS
DLS = depth limit search: we stop at limit L depth. not optimal
IDS = ???

bidirectional search
- search from initial state. search from goal state. see if they meet in the middle
- if we know both states, but we dont know how to get from initial to goal
- interesting algo because it can save a lot of time
  - original time = b^d. new time = b^(d/2) * 2
  - this is much less than b^d. so this might be really good.
  - downsides = keep memory of entire frontier to compare which ones match up at midpoint
  
  - only works when we have a goal state and not a goal predicate (n queens does not work)
uniform cost search
- to maintain optimality make sure to check goal state in the generate stage

# Lecture 6
Informed search
- heuristic search motivation
- we have some heuristic function = estimate of the actual answers
- greedy best first search = best algorithm
  - 6 min 23 seconds for walkthrough of ^^
- first pass might not be optimal even though it's greedy)
- not optimal. complete (if we make sure to not revisit old paths)
  - otherwise it is infinite paths
^^ greedy algo is TOO greedy
uniform cost search with cost g(n) is too conservative
A* search!!!!! = solution
- simultaneously use g(n) = distance from start and h(n) heuristic
  - g(n) + h(n)
  - h*(n) >= h(n) if h is optimistic.
  - while recursing, every road has to have at least the min value otherwise it is the min value
- running the algorithm 22 min 12 seconds
  - difference from greedy at 32 minutes 0 seconds
- guaranteed to be optimal

IDA* = search by distance (end of lecture didn't really understand or watch)

